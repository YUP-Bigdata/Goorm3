The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization.
The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'.
The class this function is called from is 'KoBertTokenizer'.
The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization.
The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'.
The class this function is called from is 'PreTrainedTokenizerFast'.
Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']
- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at skt/kogpt2-base-v2 and are newly initialized: ['transformer.h.5.crossattention.c_attn.weight', 'transformer.h.5.crossattention.masked_bias', 'transformer.h.3.crossattention.c_proj.bias', 'transformer.h.6.crossattention.c_attn.weight', 'transformer.h.10.crossattention.c_proj.bias', 'transformer.h.0.crossattention.c_attn.weight', 'transformer.h.7.crossattention.c_proj.weight', 'transformer.h.5.ln_cross_attn.weight', 'transformer.h.0.crossattention.bias', 'transformer.h.0.crossattention.q_attn.weight', 'transformer.h.3.ln_cross_attn.weight', 'transformer.h.9.crossattention.q_attn.weight', 'transformer.h.2.crossattention.q_attn.weight', 'transformer.h.2.ln_cross_attn.weight', 'transformer.h.7.crossattention.c_proj.bias', 'transformer.h.10.crossattention.q_attn.weight', 'transformer.h.4.crossattention.c_attn.weight', 'transformer.h.11.crossattention.q_attn.weight', 'transformer.h.9.crossattention.bias', 'transformer.h.7.crossattention.c_attn.weight', 'transformer.h.1.crossattention.c_attn.weight', 'transformer.h.0.crossattention.c_proj.bias', 'transformer.h.7.crossattention.bias', 'transformer.h.6.crossattention.bias', 'transformer.h.2.crossattention.c_proj.bias', 'transformer.h.1.crossattention.c_proj.bias', 'transformer.h.4.crossattention.masked_bias', 'transformer.h.11.crossattention.c_proj.bias', 'transformer.h.9.crossattention.c_attn.weight', 'transformer.h.9.ln_cross_attn.weight', 'transformer.h.8.crossattention.masked_bias', 'transformer.h.0.ln_cross_attn.weight', 'transformer.h.4.crossattention.bias', 'transformer.h.10.crossattention.c_attn.weight', 'transformer.h.6.crossattention.c_proj.weight', 'transformer.h.9.crossattention.c_proj.bias', 'transformer.h.4.crossattention.c_proj.weight', 'transformer.h.9.crossattention.c_proj.weight', 'transformer.h.10.crossattention.masked_bias', 'transformer.h.1.crossattention.c_proj.weight', 'transformer.h.1.crossattention.masked_bias', 'transformer.h.8.ln_cross_attn.weight', 'transformer.h.11.crossattention.masked_bias', 'transformer.h.2.crossattention.c_attn.weight', 'transformer.h.6.crossattention.masked_bias', 'transformer.h.11.crossattention.c_attn.weight', 'transformer.h.7.ln_cross_attn.weight', 'transformer.h.2.crossattention.bias', 'transformer.h.7.crossattention.masked_bias', 'transformer.h.8.crossattention.c_attn.weight', 'transformer.h.5.crossattention.q_attn.weight', 'transformer.h.8.crossattention.bias', 'transformer.h.5.crossattention.bias', 'transformer.h.3.crossattention.masked_bias', 'transformer.h.4.crossattention.c_proj.bias', 'transformer.h.6.crossattention.q_attn.weight', 'transformer.h.6.ln_cross_attn.weight', 'transformer.h.0.crossattention.c_proj.weight', 'transformer.h.5.crossattention.c_proj.weight', 'transformer.h.8.crossattention.c_proj.weight', 'transformer.h.10.ln_cross_attn.weight', 'transformer.h.3.crossattention.q_attn.weight', 'transformer.h.0.crossattention.masked_bias', 'transformer.h.4.crossattention.q_attn.weight', 'transformer.h.3.crossattention.bias', 'transformer.h.6.crossattention.c_proj.bias', 'transformer.h.2.crossattention.c_proj.weight', 'transformer.h.2.crossattention.masked_bias', 'transformer.h.8.crossattention.c_proj.bias', 'transformer.h.8.crossattention.q_attn.weight', 'transformer.h.11.crossattention.c_proj.weight', 'transformer.h.1.ln_cross_attn.weight', 'transformer.h.3.crossattention.c_proj.weight', 'transformer.h.10.crossattention.c_proj.weight', 'transformer.h.3.crossattention.c_attn.weight', 'transformer.h.4.ln_cross_attn.weight', 'transformer.h.1.crossattention.bias', 'transformer.h.5.crossattention.c_proj.bias', 'transformer.h.11.ln_cross_attn.weight', 'transformer.h.7.crossattention.q_attn.weight', 'transformer.h.11.crossattention.bias', 'transformer.h.10.crossattention.bias', 'transformer.h.1.crossattention.q_attn.weight', 'transformer.h.9.crossattention.masked_bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
['괜찮지만 괜찮지 않아 익숙하다고 혼잣말했지만 늘 처음인 것처럼 아파', "I'm okay but I'm not okay I told myself I'm used to it But I'm in pain like it's the first time"]
['얼마큼 나를 버려야 하니 서럽게 우는 내 맘 들리니 널 미친 듯 안고 싶은데 너 없이 나 견디지 못해', 'How much more do I have to throw myself away? Can you hear my sobbing heart? I want to hug you like crazy I can’t stand it without you']
{'input_ids': [101, 100, 100, 100, 1463, 30019, 30020, 29997, 30014, 30020, 30005, 30006, 29993, 30006, 29991, 30011, 100, 1456, 30017, 30022, 1465, 30008, 29999, 30017, 30023, 29999, 30019, 30021, 100, 1463, 30006, 30004, 30006, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [10054, 382, 451, 10288, 449, 14778, 13726, 14197, 10054, 382, 451, 14415, 13650, 10288, 449, 14778, 10054, 10448, 27149, 11849, 22070, 10630, 444, 10054, 382, 451, 739, 10567, 11517, 20938, 739, 10455, 9707, 14197, 10054, 382, 451, 13799, 11553, 22495, 13008, 21964, 443, 739, 10455, 16239, 11370, 13063, 13019, 13394, 739, 9768, 21135]}
['[CLS]', '[UNK]', '[UNK]', '[UNK]', 'ᄋ', '##ᅵ', '##ᆨ', '##ᄉ', '##ᅮ', '##ᆨ', '##ᄒ', '##ᅡ', '##ᄃ', '##ᅡ', '##ᄀ', '##ᅩ', '[UNK]', 'ᄂ', '##ᅳ', '##ᆯ', 'ᄎ', '##ᅥ', '##ᄋ', '##ᅳ', '##ᆷ', '##ᄋ', '##ᅵ', '##ᆫ', '[UNK]', 'ᄋ', '##ᅡ', '##ᄑ', '##ᅡ', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']
['▁I', "'", 'm', '▁o', 'k', 'ay', '▁b', 'ut', '▁I', "'", 'm', '▁n', 'ot', '▁o', 'k', 'ay', '▁I', '▁t', 'old', '▁m', 'ys', 'el', 'f', '▁I', "'", 'm', '▁', 'us', 'ed', '▁to', '▁', 'it', '▁B', 'ut', '▁I', "'", 'm', '▁in', '▁p', 'ain', '▁l', 'ik', 'e', '▁', 'it', "'s", '▁the', '▁f', 'ir', 'st', '▁', 'ti', 'me']
{'input_ids': [739, 6910, 8338, 9176, 739, 6910, 8338, 8263, 11492, 31077, 12524, 9749, 8166, 7492, 12357, 10061, 9609, 8148, 12499, 16484, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], 'labels': [101, 1045, 1005, 1049, 3100, 2021, 1045, 1005, 1049, 2025, 3100, 1045, 2409, 2870, 1045, 1005, 1049, 2109, 2000, 2009, 2021, 1045, 1005, 1049, 1999, 3255, 2066, 2009, 1005, 1055, 1996, 2034, 2051, 102]}
['[unused734]', 'colored', 'succession', '1847', '[unused734]', 'colored', 'succession', 'qualification', 'macedonia', '[UNK]', 'rented', 'archived', 'ottawa', 'speakers', '1816', 'abstract', 'sunshine', '160', 'painters', 'curiously', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]', '[unused2]']
['<unused92>', '伯', '仁', '伸', '梡', '寗', '伯', '仁', '伸', '寡', '梡', '伯', '恐', '昊', '伯', '仁', '伸', '峋', '宰', '寀', '寗', '伯', '仁', '伸', '宮', '櫂', '尻', '寀', '仁', '佇', '宦', '寬', '對', '<unused93>']
{'input_ids': [101, 100, 100, 100, 1463, 30019, 30020, 29997, 30014, 30020, 30005, 30006, 29993, 30006, 29991, 30011, 100, 1456, 30017, 30022, 1465, 30008, 29999, 30017, 30023, 29999, 30019, 30021, 100, 1463, 30006, 30004, 30006, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [10054, 382, 451, 10288, 449, 14778, 13726, 14197, 10054, 382, 451, 14415, 13650, 10288, 449, 14778, 10054, 10448, 27149, 11849, 22070, 10630, 444, 10054, 382, 451, 739, 10567, 11517, 20938, 739, 10455, 9707, 14197, 10054, 382, 451, 13799, 11553, 22495, 13008, 21964, 443, 739, 10455, 16239, 11370, 13063, 13019, 13394, 739, 9768, 21135]}
['[CLS]', '[UNK]', '[UNK]', '[UNK]', 'ᄋ', '##ᅵ', '##ᆨ', '##ᄉ', '##ᅮ', '##ᆨ', '##ᄒ', '##ᅡ', '##ᄃ', '##ᅡ', '##ᄀ', '##ᅩ', '[UNK]', 'ᄂ', '##ᅳ', '##ᆯ', 'ᄎ', '##ᅥ', '##ᄋ', '##ᅳ', '##ᆷ', '##ᄋ', '##ᅵ', '##ᆫ', '[UNK]', 'ᄋ', '##ᅡ', '##ᄑ', '##ᅡ', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']
['▁I', "'", 'm', '▁o', 'k', 'ay', '▁b', 'ut', '▁I', "'", 'm', '▁n', 'ot', '▁o', 'k', 'ay', '▁I', '▁t', 'old', '▁m', 'ys', 'el', 'f', '▁I', "'", 'm', '▁', 'us', 'ed', '▁to', '▁', 'it', '▁B', 'ut', '▁I', "'", 'm', '▁in', '▁p', 'ain', '▁l', 'ik', 'e', '▁', 'it', "'s", '▁the', '▁f', 'ir', 'st', '▁', 'ti', 'me']
Using amp half precision backend
/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  FutureWarning,
***** Running training *****
  Num examples = 12088
  Num Epochs = 10
  Instantaneous batch size per device = 4
  Total train batch size (w. parallel, distributed & accumulation) = 256
  Gradient Accumulation steps = 64
  Total optimization steps = 470
Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:530: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.
