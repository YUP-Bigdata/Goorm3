Some weights of the model checkpoint at monologg/kobigbird-bert-base were not used when initializing BigBirdForQuestionAnswering: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'bert.pooler.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'bert.pooler.bias']
- This IS expected if you are initializing BigBirdForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BigBirdForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BigBirdForQuestionAnswering were not initialized from the model checkpoint at monologg/kobigbird-bert-base and are newly initialized: ['qa_classifier.output.dense.weight', 'qa_classifier.output.LayerNorm.bias', 'qa_classifier.intermediate.dense.weight', 'qa_classifier.qa_outputs.bias', 'qa_classifier.intermediate.dense.bias', 'qa_classifier.qa_outputs.weight', 'qa_classifier.output.LayerNorm.weight', 'qa_classifier.output.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Number of Samples: 12037 243425 100268
Number of Train Samples: 10834 219083 90242
Number of Dev Samples: 1203 24342 10026
Number of Train Samples: 1440
Number of Dev Samples: 159
Number of Samples: 12037 243425 100268
Number of Train Samples: 10834 219083 90242
Number of Dev Samples: 1203 24342 10026
Number of Train Samples: 11778
Number of Dev Samples: 1308
Number of Samples: 12037 243425 100268
Number of Train Samples: 10834 219083 90242
Number of Dev Samples: 1203 24342 10026
Number of Train Samples: 58006
Number of Dev Samples: 6445
Number of Samples: 12037 243425 100268
Number of Train Samples: 10834 219083 90242
Number of Dev Samples: 1203 24342 10026
Number of Train Samples: 34863
Number of Dev Samples: 3873
['김경수', '봉하', '사업', '본부', '장', '도', '연합뉴스', '와', '통화', '에서', '"', '노', '전', '대통령', '이', '합의', '하', '지도', '않', '은', '북한', '의', '일방', '적', '주장', '을', '합의', '사항', '으로', '만들', '어버', '린', '매', '국적', '국정원', '"', '이라', '며', '"', '국정원', '은', '난', '독', '증', '환자', '인', '가', '"', '라고', '비판', '했', '다', '.']
['김경수', '봉하', '사업', '본부', '장', '도', '연합뉴스', '와', '통화', '에서', '"', '노', '전', '대통령', '이', '합의', '하', '지도', '않', '은', '북한', '의', '일방', '적', '주장', '을', '합의', '사항', '으로', '만들', '어버', '린', '매', '국적', '국정원', '"', '이라', '며', '"', '국정원', '은', '난', '독', '증', '환자', '인', '가', '"', '라고', '비판', '했', '다', '.']
{'guid': 'a89fcc2e93f843d9ae8d017e10288b1c', 'context_original': '민주당은 국가정보원이 10일 대변인 성명을 통해 "2007년 남북정상회담에서 노무현 전 대통령이 서해북방한계선(NLL)을 포기했다"고 재차 주장한 것과 관련 묵과할 수 없다며 분노를 표시했다. 2007년 정상회담 당시 통일부장관 정책보좌관을 했던 민주당 홍익표 의원은 정치생명을 걸고 투쟁하겠다고 했다. 홍 의원은 11일 내일신문과 통화에서 "나쁜 결정이지만 국회의원 2/3가 결정해 대통령 기록물을 보기로 한 만큼 이번 기회에 지난 100년간 지배해 온 친일반공세력과 전면적인 전쟁을 한다는 생각으로 임하겠다"면서 "문재인 의원과도 이미 상의를 했고, 정치생명을 걸고 싸우겠다"고 했다. 홍 의원은 "당시 정상회담 직후 남북 국방장관회담에 참석한 김장수 현 청와대 국가안보실장이 누구보다도 노 전 대통령이 NLL을 포기하지 않았다는 것을 잘 알고 있다"며 "김 실장이 이에 대한 진실을 밝혀야 한다"고도 했다. 정상회담 당시 청와대 연설기획비서관을 한 \'노무현재단\' 김경수 봉하사업본부장도 연합뉴스와 통화에서 "노 전 대통령이 합의하지도 않은 북한의 일방적 주장을 합의사항으로 만들어버린 매국적 국정원"이라며 "국정원은 난독증 환자인가"라고 비판했다. 민주당 배재정 대변인도 "국정원이 조직을 살리기 위해 꼼수를 부리며 국민과 전면전을 선포하는 것인가"라며 "국정원이 꼼수로 조직의 위기상황을 모면하려고 한다면 강력한 국민적 저항에 부딪치게 될 것임을 경고한다"고 했다.', 'context_position': [(0, 3), (3, 4), (5, 7), (7, 9), (9, 10), (10, 11), (12, 14), (14, 15), (16, 19), (20, 22), (22, 23), (24, 26), (27, 28), (28, 32), (32, 33), (34, 36), (36, 37), (37, 38), (38, 39), (39, 40), (40, 42), (43, 46), (47, 48), (49, 52), (52, 53), (54, 56), (56, 57), (57, 58), (58, 59), (59, 61), (61, 62), (62, 65), (65, 66), (66, 67), (68, 70), (70, 71), (71, 72), (72, 73), (73, 74), (75, 77), (78, 80), (80, 81), (82, 83), (83, 84), (85, 87), (88, 89), (89, 90), (90, 91), (92, 93), (94, 95), (95, 96), (96, 97), (98, 100), (100, 101), (102, 104), (104, 105), (105, 106), (106, 107), (108, 112), (112, 113), (114, 116), (116, 117), (117, 118), (119, 121), (122, 125), (125, 126), (126, 127), (128, 130), (130, 131), (131, 132), (132, 133), (133, 134), (135, 136), (136, 137), (138, 141), (142, 144), (144, 145), (146, 148), (148, 149), (150, 152), (152, 154), (154, 155), (156, 157), (157, 158), (159, 161), (161, 162), (162, 164), (164, 165), (166, 167), (167, 168), (168, 169), (170, 171), (172, 174), (174, 175), (176, 178), (178, 179), (180, 182), (182, 184), (184, 185), (186, 188), (188, 190), (191, 192), (192, 194), (195, 197), (197, 199), (199, 200), (201, 205), (206, 207), (207, 208), (208, 209), (209, 210), (211, 213), (213, 214), (215, 218), (219, 222), (222, 223), (224, 225), (225, 226), (226, 227), (228, 229), (230, 232), (233, 235), (236, 238), (238, 239), (240, 242), (243, 246), (246, 247), (247, 248), (249, 251), (251, 252), (253, 254), (255, 257), (257, 258), (258, 259), (259, 260), (260, 261), (261, 262), (263, 265), (265, 266), (266, 267), (268, 270), (270, 271), (272, 275), (276, 278), (278, 280), (281, 283), (283, 285), (285, 286), (286, 288), (289, 290), (290, 293), (294, 296), (296, 297), (297, 298), (299, 301), (302, 304), (304, 305), (306, 307), (307, 308), (308, 309), (310, 312), (312, 314), (314, 315), (316, 317), (317, 318), (319, 321), (321, 323), (323, 324), (324, 325), (326, 327), (327, 328), (328, 329), (330, 331), (332, 334), (334, 335), (336, 337), (337, 339), (340, 342), (342, 343), (343, 344), (345, 347), (348, 350), (351, 353), (353, 354), (354, 355), (355, 356), (356, 357), (357, 358), (359, 361), (361, 362), (363, 365), (365, 366), (367, 368), (369, 372), (373, 375), (375, 376), (376, 377), (377, 378), (378, 380), (381, 383), (383, 384), (384, 385), (385, 386), (387, 388), (389, 390), (391, 394), (394, 395), (396, 399), (399, 400), (401, 403), (403, 404), (404, 405), (406, 407), (407, 408), (408, 410), (411, 412), (412, 413), (414, 415), (416, 418), (419, 420), (420, 421), (421, 422), (422, 423), (424, 425), (425, 426), (427, 429), (429, 430), (431, 433), (434, 436), (437, 439), (439, 440), (441, 444), (445, 447), (447, 448), (448, 450), (451, 452), (452, 453), (453, 454), (455, 457), (457, 458), (458, 459), (460, 462), (463, 466), (467, 469), (469, 471), (471, 472), (472, 474), (474, 475), (476, 477), (478, 479), (479, 482), (482, 484), (484, 485), (486, 489), (490, 492), (492, 494), (494, 496), (496, 497), (497, 498), (499, 503), (503, 504), (505, 507), (507, 509), (510, 511), (511, 512), (513, 514), (515, 518), (518, 519), (520, 522), (522, 523), (523, 525), (526, 527), (527, 528), (529, 531), (531, 532), (533, 535), (535, 536), (537, 539), (539, 540), (541, 543), (543, 545), (545, 547), (548, 550), (550, 552), (552, 553), (554, 555), (555, 557), (558, 561), (561, 562), (562, 564), (564, 565), (566, 567), (567, 570), (570, 571), (572, 573), (573, 574), (574, 575), (576, 578), (578, 579), (579, 580), (580, 581), (581, 583), (584, 586), (586, 587), (587, 588), (588, 589), (590, 593), (594, 596), (596, 597), (598, 601), (601, 602), (603, 604), (604, 607), (607, 608), (609, 611), (611, 612), (613, 615), (615, 616), (617, 619), (620, 622), (622, 623), (624, 626), (626, 627), (628, 630), (630, 631), (632, 635), (635, 636), (637, 639), (639, 640), (640, 641), (642, 643), (643, 644), (644, 645), (645, 646), (646, 648), (649, 650), (650, 653), (653, 654), (655, 657), (657, 658), (659, 661), (661, 662), (663, 665), (665, 666), (666, 667), (667, 668), (669, 671), (671, 672), (672, 674), (675, 678), (679, 681), (681, 682), (683, 685), (685, 686), (687, 689), (689, 690), (691, 694), (694, 695), (696, 697), (698, 699), (699, 700), (700, 701), (702, 704), (704, 706), (706, 707), (707, 708), (709, 710), (710, 711), (711, 712)], 'question_original': '김경수 봉하사업본부장도 연합뉴스와 통화에서 무어라 비판했나', 'context': ['민주당', '은', '국가', '정보', '원', '이', '10', '일', '대변인', '성명', '을', '통해', '"', '2007', '년', '남북', '정', '상', '회', '담', '에서', '노무현', '전', '대통령', '이', '서해', '북', '방', '한', '계선', '(', 'NLL', ')', '을', '포기', '했', '다', '"', '고', '재차', '주장', '한', '것', '과', '관련', '묵', '과', '할', '수', '없', '다', '며', '분노', '를', '표시', '했', '다', '.', '2007', '년', '정상', '회', '담', '당시', '통일부', '장', '관', '정책', '보', '좌', '관', '을', '했', '던', '민주당', '홍익', '표', '의원', '은', '정치', '생명', '을', '걸', '고', '투쟁', '하', '겠다', '고', '했', '다', '.', '홍', '의원', '은', '11', '일', '내일', '신문', '과', '통화', '에서', '"', '나쁜', '결정', '이지', '만', '국회의원', '2', '/', '3', '가', '결정', '해', '대통령', '기록물', '을', '보', '기', '로', '한', '만큼', '이번', '기회', '에', '지난', '100', '년', '간', '지배', '해', '온', '친일', '반', '공', '세', '력', '과', '전면', '적', '인', '전쟁', '을', '한다는', '생각', '으로', '임하', '겠다', '"', '면서', '"', '문재인', '의원', '과', '도', '이미', '상의', '를', '했', '고', ',', '정치', '생명', '을', '걸', '고', '싸우', '겠다', '"', '고', '했', '다', '.', '홍', '의원', '은', '"', '당시', '정상', '회', '담', '직후', '남북', '국방', '장', '관', '회', '담', '에', '참석', '한', '김장', '수', '현', '청와대', '국가', '안', '보', '실', '장이', '누구', '보', '다', '도', '노', '전', '대통령', '이', 'NLL', '을', '포기', '하', '지', '않', '았', '다는', '것', '을', '잘', '알고', '있', '다', '"', '며', '"', '김', '실장', '이', '이에', '대한', '진실', '을', '밝혀야', '한다', '"', '고도', '했', '다', '.', '정상', '회', '담', '당시', '청와대', '연설', '기획', '비', '서관', '을', '한', "'", '노무현', '재단', "'", '김경수', '봉하', '사업', '본부', '장', '도', '연합뉴스', '와', '통화', '에서', '"', '노', '전', '대통령', '이', '합의', '하', '지도', '않', '은', '북한', '의', '일방', '적', '주장', '을', '합의', '사항', '으로', '만들', '어버', '린', '매', '국적', '국정원', '"', '이라', '며', '"', '국정원', '은', '난', '독', '증', '환자', '인', '가', '"', '라고', '비판', '했', '다', '.', '민주당', '배재', '정', '대변인', '도', '"', '국정원', '이', '조직', '을', '살리', '기', '위해', '꼼수', '를', '부리', '며', '국민', '과', '전면전', '을', '선포', '하', '는', '것', '인', '가', '"', '라며', '"', '국정원', '이', '꼼수', '로', '조직', '의', '위기', '상', '황', '을', '모면', '하', '려고', '한다면', '강력', '한', '국민', '적', '저항', '에', '부딪치', '게', '될', '것', '임', '을', '경고', '한다', '"', '고', '했', '다', '.'], 'question': ['김경수', '봉하', '##사업', '##본부', '##장', '##도', '연합뉴스', '##와', '통화', '##에서', '무어', '##라', '비판', '##했', '##나'], 'answers': [{'start': 253, 'end': 305}]}
tensor([[    2, 15982,  4777,  ...,     0,     0,     0],
        [    2, 17697,  4629,  ...,  3808,  2856,     3],
        [    2,  8235,  4540,  ...,     0,     0,     0],
        [    2,  7741,  7203,  ...,     0,     0,     0]])
torch.Size([4, 1024])
['guid', 'context', 'question', 'position', 'input_ids', 'token_type_ids', 'start', 'end', 'attention_mask']
/usr/local/lib/python3.7/dist-packages/transformers/models/big_bird/modeling_big_bird.py:978: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  * num_indices_to_pick_from
Attention type 'block_sparse' is not possible if sequence_length: 592 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...
